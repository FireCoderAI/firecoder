name: Build Server

on:
  push:
    branches:
      - "add-ci"
  workflow_dispatch:
    inputs:
      llama-tag:
        description: "llama.cpp tag"
        required: true
        type: string
        default: "b1775"

env:
  LLAMA-TAG: "b1775"

jobs:
  build-cmake-linux:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_STATIC=ON
          cmake --build . --config Release --parallel $(nproc)

      - name: Test
        run: |
          cd build
          ctest --verbose --timeout 900

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-linux-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-linux-cublas:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential

      - name: Install cuda-toolkit
        run: |
          sudo apt-get update
          sudo apt-get -y install nvidia-cuda-toolkit

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_CUBLAS=ON 
          cmake --build . --config Release --parallel $(nproc)

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-linux-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-windows:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_STATIC=ON
          cmake --build . --config Release --parallel ${env:NUMBER_OF_PROCESSORS}

      - name: Test
        run: |
          cd build
          ctest -C Release --verbose --timeout 900

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-windows-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/Release/server.exe
          retention-days: 1

  build-cmake-windows-cublas:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install cuda-toolkit
        uses: Jimver/cuda-toolkit@v0.2.11
        with:
          cuda: "12.2.0"
          method: "network"
          sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_CUBLAS=ON -DLLAMA_STATIC=ON
          cmake --build . --config Release --parallel ${env:NUMBER_OF_PROCESSORS}

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-windows-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/Release/server.exe
          retention-days: 1

  build-cmake-macOS:
    runs-on: macos-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          brew update

      - name: Build
        run: |
          sysctl -a
          mkdir build
          cd build
          cmake -DLLAMA_METAL=OFF ..
          cmake --build . --config Release --parallel $(sysctl -n hw.logicalcpu)

      - name: Test
        id: cmake_test
        run: |
          cd build
          ctest --verbose --timeout 900

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-macOS-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-macOS-metal:
    runs-on: macos-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          brew update

      - name: Build
        run: |
          sysctl -a
          mkdir build
          cd build
          cmake ..
          cmake --build . --config Release --parallel $(sysctl -n hw.logicalcpu)

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-macOS-metal-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  upload-server:
    runs-on: ubuntu-latest
    needs:
      - build-cmake-linux
      - build-cmake-linux-cublas
      - build-cmake-windows
      - build-cmake-windows-cublas
      - build-cmake-macOS
      - build-cmake-macOS-metal

    steps:
      - name: Install minio
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x ./mc
          ./mc alias set r2 ${{ secrets.AWS_ENDPOINT }} ${{ secrets.AWS_KEY_ID }} ${{ secrets.AWS_SECRET_ACCESS_KEY}}

      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-linux-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-linux
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-linux-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-linux-cublas
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-windows-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-windows
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-windows-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-windows-cublas
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-macOS-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-macOS
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-macOS-metal-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-macOS-metal

      - name: Upload
        run: |
          ./mc cp ./build-cmake-linux/server              r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/linux-x86-64
          ./mc cp ./build-cmake-linux-cublas/server       r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/linux-x86-64-cublas
          ./mc cp ./build-cmake-windows/server.exe        r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/windows-x86-64
          ./mc cp ./build-cmake-windows-cublas/server.exe r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/windows-x86-64-cublas
          ./mc cp ./build-cmake-macOS/server              r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/macOS-x86-64
          ./mc cp ./build-cmake-macOS-metal/server        r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/macOS-x86-64-metal
      - name: Create version spec
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const crypto = require("crypto");

            const s3Path = 'https://pub-ad9e0b7360bc4259878d0f81b89c5405.r2.dev/${{ github.sha }}/${{env.LLAMA-TAG}}/';

            const getCheckSum = (path) => {
              const file = fs.readFileSync(path);

              const hash = crypto.createHash("sha256").update(file).digest("hex");

              return hash;
            };

            const spec = {
              linux: {
                "x86-64": {
                  cpu: {
                    checksum: getCheckSum("./build-cmake-linux/server"),
                    url: s3Path + 'linux-x86-64',
                  },
                  cublas: {
                    checksum: getCheckSum("./build-cmake-linux-cublas/server"),
                    url: s3Path + 'linux-x86-64-cublas'
                  },
                }
              },
              win32: {
                "x86-64": {
                  cpu: {
                    checksum: getCheckSum("./build-cmake-windows/server.exe"),
                    url: s3Path + 'windows-x86-64',
                  },
                  cublas: {
                    checksum: getCheckSum("./build-cmake-windows-cublas/server.exe"),
                    url: s3Path + 'windows-x86-64-cublas'
                  },
                }
              },
              darwin: {
                "x86-64": {
                  cpu: {
                    checksum: getCheckSum("./build-cmake-macOS/server"),
                    url: s3Path + 'macOS-x86-64',
                  },
                  metal: {
                    checksum: getCheckSum("./build-cmake-macOS-metal/server"),
                    url: s3Path + 'macOS-x86-64-metal'
                  },
                }
              }
            };
            console.log(JSON.stringify(spec, null, 2))
            fs.writeFileSync('spec.json', JSON.stringify(spec));

      - name: Upload spec
        run: |
          ./mc cp ./spec.json r2/${{secrets.AWS_BUCKET}}/spec.json
