name: Build Server

on:
  push:
    branches:
      - "add-ci"
  workflow_dispatch:
    inputs:
      llama-tag:
        description: "llama.cpp tag"
        required: true
        type: string
        default: "b1768"

env:
  LLAMA-TAG: "b1768"

jobs:
  build-cmake-ubuntu:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF
          cmake --build . --config Release --parallel $(nproc)

      - name: Test
        run: |
          cd build
          ctest --verbose --timeout 900

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-ubuntu-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-ubuntu-cublas:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install build-essential

      - name: Install cuda-toolkit
        run: |
          sudo apt-get update
          sudo apt-get -y install nvidia-cuda-toolkit

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_CUBLAS=ON
          cmake --build . --config Release --parallel $(nproc)

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-ubuntu-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-windows:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}
      - name: Windows GitHub Actions environment variables List
        run: env
      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF
          cmake --build . --config Release --parallel ${env:NUMBER_OF_PROCESSORS}
      - name: Test
        run: |
          cd build
          ctest -C Release --verbose --timeout 900

      - run: |
          ls 
          ls build
      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-windows-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-windows-cublas:
    runs-on: windows-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install cuda-toolkit
        uses: Jimver/cuda-toolkit@v0.2.11
        with:
          cuda: "12.2.0"
          method: "network"
          sub-packages: '["nvcc", "cudart", "cublas", "cublas_dev", "thrust", "visual_studio_integration"]'

      - name: Build
        run: |
          mkdir build
          cd build
          cmake .. -DBUILD_SHARED_LIBS=ON -DLLAMA_BUILD_SERVER=ON -DLLAMA_NATIVE=OFF -DLLAMA_CUBLAS=ON
          cmake --build . --config Release --parallel ${env:NUMBER_OF_PROCESSORS}

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-windows-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-macOS:
    runs-on: macos-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          brew update

      - name: Build
        run: |
          sysctl -a
          mkdir build
          cd build
          cmake -DLLAMA_METAL=OFF ..
          cmake --build . --config Release --parallel $(sysctl -n hw.logicalcpu)

      - name: Test
        id: cmake_test
        run: |
          cd build
          ctest --verbose --timeout 900

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-macOS-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  build-cmake-macOS-metal:
    runs-on: macos-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: "ggerganov/llama.cpp"
          ref: ${{ env.LLAMA-TAG }}

      - name: Install dependencies
        run: |
          brew update

      - name: Build
        run: |
          sysctl -a
          mkdir build
          cd build
          cmake ..
          cmake --build . --config Release --parallel $(sysctl -n hw.logicalcpu)

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: build-cmake-macOS-metal-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: build/bin/server
          retention-days: 1

  upload-server:
    runs-on: ubuntu-latest
    needs:
      - build-cmake-ubuntu
      - build-cmake-ubuntu-cublas
      - build-cmake-windows
      - build-cmake-windows-cublas
      - build-cmake-macOS
      - build-cmake-macOS-metal

    steps:
      - name: Install minio
        run: |
          wget https://dl.min.io/client/mc/release/linux-amd64/mc
          chmod +x ./mc
          ./mc alias set r2 ${{ secrets.AWS_ENDPOINT }} ${{ secrets.AWS_KEY_ID }} ${{ secrets.AWS_SECRET_ACCESS_KEY}}

      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-ubuntu-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-ubuntu
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-ubuntu-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-ubuntu-cublas
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-windows-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-windows
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-windows-cublas-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-windows-cublas
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-macOS-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-macOS
      - uses: actions/download-artifact@v4
        with:
          name: build-cmake-macOS-metal-${{env.LLAMA-TAG}}-${{ github.sha }}
          path: ./build-cmake-macOS-metal

      - name: Upload
        run: |
          ./mc cp ./build-cmake-ubuntu/server         r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/linux-x86-64
          ./mc cp ./build-cmake-ubuntu-cublas/server  r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/linux-x86-64-cublas
          ./mc cp ./build-cmake-windows/server        r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/windows-x86-64
          ./mc cp ./build-cmake-windows-cublas/server r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/windows-x86-64-cublas
          ./mc cp ./build-cmake-macOS/server          r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/macOS-x86-64
          ./mc cp ./build-cmake-macOS-metal/server    r2/${{secrets.AWS_BUCKET}}/${{ github.sha }}/${{env.LLAMA-TAG}}/macOS-x86-64-metal
